<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>huijun's blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">huijun's blog</h1><a id="logo" href="/.">huijun's blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h2 class="post-title"><a href="/2016/12/15/Mysql5-6-GTID-半同步复制配置/">Mysql5.6 GTID 半同步复制配置</a></h2><div class="post-meta">2016-12-15</div><div class="post-content"><h4 id="半同步复制原理：确保至少一个slave将变更写到磁盘，也就是说，对于每一个连接来说如果发生master崩溃，之多丢失一个事务。一定要理解半同步复制不会阻塞事务的提交，而是知道事务写入至少一个slave中继日志猜想客户端发送响应。对于每一个连接，如果事务提交到存储引擎之后，发送到slave之前，发生系统崩溃，那么这个事务就会丢失，但是在slave确定事务提交之后才会想客户端发送确认，所以至多会丢失一个事务，通常一个客户端只会丢失一个事务。"><a href="#半同步复制原理：确保至少一个slave将变更写到磁盘，也就是说，对于每一个连接来说如果发生master崩溃，之多丢失一个事务。一定要理解半同步复制不会阻塞事务的提交，而是知道事务写入至少一个slave中继日志猜想客户端发送响应。对于每一个连接，如果事务提交到存储引擎之后，发送到slave之前，发生系统崩溃，那么这个事务就会丢失，但是在slave确定事务提交之后才会想客户端发送确认，所以至多会丢失一个事务，通常一个客户端只会丢失一个事务。" class="headerlink" title="半同步复制原理：确保至少一个slave将变更写到磁盘，也就是说，对于每一个连接来说如果发生master崩溃，之多丢失一个事务。一定要理解半同步复制不会阻塞事务的提交，而是知道事务写入至少一个slave中继日志猜想客户端发送响应。对于每一个连接，如果事务提交到存储引擎之后，发送到slave之前，发生系统崩溃，那么这个事务就会丢失，但是在slave确定事务提交之后才会想客户端发送确认，所以至多会丢失一个事务，通常一个客户端只会丢失一个事务。"></a>半同步复制原理：确保至少一个slave将变更写到磁盘，也就是说，对于每一个连接来说如果发生master崩溃，之多丢失一个事务。一定要理解半同步复制不会阻塞事务的提交，而是知道事务写入至少一个slave中继日志猜想客户端发送响应。对于每一个连接，如果事务提交到存储引擎之后，发送到slave之前，发生系统崩溃，那么这个事务就会丢失，但是在slave确定事务提交之后才会想客户端发送确认，所以至多会丢失一个事务，通常一个客户端只会丢失一个事务。</h4><h4 id="半同步复制需要应对两种情况？"><a href="#半同步复制需要应对两种情况？" class="headerlink" title="半同步复制需要应对两种情况？"></a>半同步复制需要应对两种情况？</h4><h5 id="1-如果所有的slave都崩溃了，无法确认事务是否写入中继日志了怎么办？如果master只连一个slave，这种情况不是不可能。"><a href="#1-如果所有的slave都崩溃了，无法确认事务是否写入中继日志了怎么办？如果master只连一个slave，这种情况不是不可能。" class="headerlink" title="1. 如果所有的slave都崩溃了，无法确认事务是否写入中继日志了怎么办？如果master只连一个slave，这种情况不是不可能。"></a>1. 如果所有的slave都崩溃了，无法确认事务是否写入中继日志了怎么办？如果master只连一个slave，这种情况不是不可能。</h5><h5 id="2-如果所有的slave连接都断开了怎么办？这时，master就无法将事务发出去。除了rpl-semi-sync-master-enable和rpl-semi-slave-enabled处理以上情况，还需要以下两个参数。"><a href="#2-如果所有的slave连接都断开了怎么办？这时，master就无法将事务发出去。除了rpl-semi-sync-master-enable和rpl-semi-slave-enabled处理以上情况，还需要以下两个参数。" class="headerlink" title="2. 如果所有的slave连接都断开了怎么办？这时，master就无法将事务发出去。除了rpl-semi-sync-master-enable和rpl-semi-slave-enabled处理以上情况，还需要以下两个参数。"></a>2. 如果所有的slave连接都断开了怎么办？这时，master就无法将事务发出去。除了rpl-semi-sync-master-enable和rpl-semi-slave-enabled处理以上情况，还需要以下两个参数。</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">rpl-semi-sync-master-timeout=milliseconds --毫秒</div><div class="line">为了防止半同步复制收不到确认被阻塞，用此选项可以设置超时设置。如果master超时仍未收到任何确认，</div><div class="line">就还原为异步复制，不再使用半同步复制。</div><div class="line"></div><div class="line">rpl-semi-sync-master-wait-no-slave=&#123;on|off&#125;</div><div class="line">如果提交的事务但master没有任何连接的slave可用，master就无法将事务发出去，</div><div class="line">默认情况下master会等slave连接在超时限制内，然后确认事务已经写入磁盘。</div></pre></td></tr></table></figure></div><p class="readmore"><a href="/2016/12/15/Mysql5-6-GTID-半同步复制配置/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/14/MySQL-误操作后如何快速恢复数据/">MySQL 误操作后如何快速恢复数据</a></h2><div class="post-meta">2016-12-14</div><div class="post-content"><h3 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h3><p>基本上每个跟数据库打交道的程序员（当然也可能是你同事）都会碰一个问题，MySQL误操作后如何快速回滚？比如，delete一张表，忘加限制条件，整张表没了。假如这还是线上环境核心业务数据，那这事就闹大了。误操作后，能快速回滚数据是非常重要的。</p></div><p class="readmore"><a href="/2016/12/14/MySQL-误操作后如何快速恢复数据/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/13/Mac上安装单机版Spark/">Mac上安装单机版Spark</a></h2><div class="post-meta">2016-12-13</div><div class="post-content"><h3 id="下载地址-http-spark-apache-org-downloads-html"><a href="#下载地址-http-spark-apache-org-downloads-html" class="headerlink" title="下载地址: http://spark.apache.org/downloads.html"></a>下载地址: <a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">http://spark.apache.org/downloads.html</a></h3><h3 id="1-点击下载地址-现在最新版本是spark-2-0-1-bin-hadoop2-7-tgz-大概180MB"><a href="#1-点击下载地址-现在最新版本是spark-2-0-1-bin-hadoop2-7-tgz-大概180MB" class="headerlink" title="1. 点击下载地址,现在最新版本是spark-2.0.1-bin-hadoop2.7.tgz ,大概180MB."></a>1. 点击下载地址,现在最新版本是spark-2.0.1-bin-hadoop2.7.tgz ,大概180MB.</h3><h3 id="2-解压下载文件-并将这个文件放大你想要的位置"><a href="#2-解压下载文件-并将这个文件放大你想要的位置" class="headerlink" title="2. 解压下载文件,并将这个文件放大你想要的位置."></a>2. 解压下载文件,并将这个文件放大你想要的位置.</h3><h3 id="3-然后这就算安装好了"><a href="#3-然后这就算安装好了" class="headerlink" title="3. 然后这就算安装好了.."></a>3. 然后这就算安装好了..</h3><p><code>mv spark-2.0.1-bin-hadoop /usr/local/</code></p></div><p class="readmore"><a href="/2016/12/13/Mac上安装单机版Spark/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/13/IntelliJ-IDEA-消除Spark程序日志中INFO输出/">IntelliJ IDEA 消除Spark程序日志中INFO输出</a></h2><div class="post-meta">2016-12-13</div><div class="post-content"><h3 id="说明-在使用Intellij-IDEA，local模式下运行Spark程序时，会在Run窗口打印出很多INFO信息，辅助信息太多可能会将有用的信息掩盖掉。如下所示"><a href="#说明-在使用Intellij-IDEA，local模式下运行Spark程序时，会在Run窗口打印出很多INFO信息，辅助信息太多可能会将有用的信息掩盖掉。如下所示" class="headerlink" title="说明: 在使用Intellij IDEA，local模式下运行Spark程序时，会在Run窗口打印出很多INFO信息，辅助信息太多可能会将有用的信息掩盖掉。如下所示"></a>说明: 在使用Intellij IDEA，local模式下运行Spark程序时，会在Run窗口打印出很多INFO信息，辅助信息太多可能会将有用的信息掩盖掉。如下所示</h3><p>这里写图片描述<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/bin/java -Didea.launcher.port=7532 &quot;-Didea.launcher.bin.path=/Applications/IntelliJ IDEA.app/Contents/bin&quot; -Dfile.encoding=UTF-8 -classpath &quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home/lib/tools.jar:/Users/luhuijun/mydoc/spark/target/classes:/Users/luhuijun/.m2/repository/org/scala-lang/scala-library/2.11.0/scala-library-2.11.0.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-core_2.11/2.0.1/spark-core_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/luhuijun/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/luhuijun/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/luhuijun/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/luhuijun/.m2/repository/com/twitter/chill_2.11/0.8.0/chill_2.11-0.8.0.jar:/Users/luhuijun/.m2/repository/com/esotericsoftware/kryo-shaded/3.0.3/kryo-shaded-3.0.3.jar:/Users/luhuijun/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/Users/luhuijun/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar:/Users/luhuijun/.m2/repository/com/twitter/chill-java/0.8.0/chill-java-0.8.0.jar:/Users/luhuijun/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-client/2.2.0/hadoop-client-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-common/2.2.0/hadoop-common-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/Users/luhuijun/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/luhuijun/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/luhuijun/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/Users/luhuijun/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/luhuijun/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/luhuijun/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/luhuijun/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-auth/2.2.0/hadoop-auth-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0.jar:/Users/luhuijun/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.2.0/hadoop-mapreduce-client-app-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.2.0/hadoop-mapreduce-client-common-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.2.0/hadoop-yarn-client-2.2.0.jar:/Users/luhuijun/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/Users/luhuijun/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/Users/luhuijun/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.2.0/hadoop-yarn-server-common-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.2.0/hadoop-mapreduce-client-shuffle-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.2.0/hadoop-yarn-api-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.2.0/hadoop-mapreduce-client-core-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.2.0/hadoop-yarn-common-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.2.0/hadoop-mapreduce-client-jobclient-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/hadoop/hadoop-annotations/2.2.0/hadoop-annotations-2.2.0.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-launcher_2.11/2.0.1/spark-launcher_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-network-common_2.11/2.0.1/spark-network-common_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Users/luhuijun/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.5/jackson-annotations-2.6.5.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-network-shuffle_2.11/2.0.1/spark-network-shuffle_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-unsafe_2.11/2.0.1/spark-unsafe_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/Users/luhuijun/.m2/repository/org/apache/curator/curator-recipes/2.4.0/curator-recipes-2.4.0.jar:/Users/luhuijun/.m2/repository/org/apache/curator/curator-framework/2.4.0/curator-framework-2.4.0.jar:/Users/luhuijun/.m2/repository/org/apache/curator/curator-client/2.4.0/curator-client-2.4.0.jar:/Users/luhuijun/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar:/Users/luhuijun/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/Users/luhuijun/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/Users/luhuijun/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/luhuijun/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/luhuijun/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/luhuijun/.m2/repository/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar:/Users/luhuijun/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/Users/luhuijun/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/Users/luhuijun/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/luhuijun/.m2/repository/org/slf4j/slf4j-log4j12/1.7.16/slf4j-log4j12-1.7.16.jar:/Users/luhuijun/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/luhuijun/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/luhuijun/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/luhuijun/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/luhuijun/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/luhuijun/.m2/repository/org/json4s/json4s-jackson_2.11/3.2.11/json4s-jackson_2.11-3.2.11.jar:/Users/luhuijun/.m2/repository/org/json4s/json4s-core_2.11/3.2.11/json4s-core_2.11-3.2.11.jar:/Users/luhuijun/.m2/repository/org/json4s/json4s-ast_2.11/3.2.11/json4s-ast_2.11-3.2.11.jar:/Users/luhuijun/.m2/repository/org/scala-lang/scalap/2.11.0/scalap-2.11.0.jar:/Users/luhuijun/.m2/repository/org/scala-lang/scala-compiler/2.11.0/scala-compiler-2.11.0.jar:/Users/luhuijun/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.1/scala-parser-combinators_2.11-1.0.1.jar:/Users/luhuijun/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/Users/luhuijun/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/Users/luhuijun/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/Users/luhuijun/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/Users/luhuijun/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/Users/luhuijun/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/Users/luhuijun/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/Users/luhuijun/.m2/repository/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/Users/luhuijun/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/Users/luhuijun/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/Users/luhuijun/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/Users/luhuijun/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/Users/luhuijun/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/Users/luhuijun/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/Users/luhuijun/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/Users/luhuijun/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.jar:/Users/luhuijun/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/Users/luhuijun/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/luhuijun/.m2/repository/io/netty/netty-all/4.0.29.Final/netty-all-4.0.29.Final.jar:/Users/luhuijun/.m2/repository/io/netty/netty/3.8.0.Final/netty-3.8.0.Final.jar:/Users/luhuijun/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/luhuijun/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/luhuijun/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/luhuijun/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/luhuijun/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/luhuijun/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.5/jackson-databind-2.6.5.jar:/Users/luhuijun/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.5/jackson-core-2.6.5.jar:/Users/luhuijun/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.11/2.6.5/jackson-module-scala_2.11-2.6.5.jar:/Users/luhuijun/.m2/repository/org/scala-lang/scala-reflect/2.11.7/scala-reflect-2.11.7.jar:/Users/luhuijun/.m2/repository/com/fasterxml/jackson/module/jackson-module-paranamer/2.6.5/jackson-module-paranamer-2.6.5.jar:/Users/luhuijun/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/luhuijun/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/luhuijun/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/luhuijun/.m2/repository/net/sf/py4j/py4j/0.10.3/py4j-0.10.3.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-tags_2.11/2.0.1/spark-tags_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/org/scalatest/scalatest_2.11/2.2.6/scalatest_2.11-2.2.6.jar:/Users/luhuijun/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/Users/luhuijun/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-sql_2.11/2.0.1/spark-sql_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/com/univocity/univocity-parsers/2.1.1/univocity-parsers-2.1.1.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-sketch_2.11/2.0.1/spark-sketch_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-catalyst_2.11/2.0.1/spark-catalyst_2.11-2.0.1.jar:/Users/luhuijun/.m2/repository/org/codehaus/janino/janino/2.7.8/janino-2.7.8.jar:/Users/luhuijun/.m2/repository/org/antlr/antlr4-runtime/4.5.3/antlr4-runtime-4.5.3.jar:/Users/luhuijun/.m2/repository/org/apache/parquet/parquet-column/1.7.0/parquet-column-1.7.0.jar:/Users/luhuijun/.m2/repository/org/apache/parquet/parquet-common/1.7.0/parquet-common-1.7.0.jar:/Users/luhuijun/.m2/repository/org/apache/parquet/parquet-encoding/1.7.0/parquet-encoding-1.7.0.jar:/Users/luhuijun/.m2/repository/org/apache/parquet/parquet-generator/1.7.0/parquet-generator-1.7.0.jar:/Users/luhuijun/.m2/repository/org/apache/parquet/parquet-hadoop/1.7.0/parquet-hadoop-1.7.0.jar:/Users/luhuijun/.m2/repository/org/apache/parquet/parquet-format/2.3.0-incubating/parquet-format-2.3.0-incubating.jar:/Users/luhuijun/.m2/repository/org/apache/parquet/parquet-jackson/1.7.0/parquet-jackson-1.7.0.jar:/Users/luhuijun/.m2/repository/org/apache/spark/spark-hive_2.11/2.0.2/spark-hive_2.11-2.0.2.jar:/Users/luhuijun/.m2/repository/com/twitter/parquet-hadoop-bundle/1.6.0/parquet-hadoop-bundle-1.6.0.jar:/Users/luhuijun/.m2/repository/org/spark-project/hive/hive-exec/1.2.1.spark2/hive-exec-1.2.1.spark2.jar:/Users/luhuijun/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/luhuijun/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/luhuijun/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/Users/luhuijun/.m2/repository/log4j/apache-log4j-extras/1.2.17/apache-log4j-extras-1.2.17.jar:/Users/luhuijun/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/Users/luhuijun/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/Users/luhuijun/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/Users/luhuijun/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/Users/luhuijun/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/luhuijun/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/luhuijun/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/Users/luhuijun/.m2/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/Users/luhuijun/.m2/repository/org/json/json/20090211/json-20090211.jar:/Users/luhuijun/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/Users/luhuijun/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/Users/luhuijun/.m2/repository/org/spark-project/hive/hive-metastore/1.2.1.spark2/hive-metastore-1.2.1.spark2.jar:/Users/luhuijun/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/Users/luhuijun/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/luhuijun/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/Users/luhuijun/.m2/repository/org/apache/derby/derby/10.10.2.0/derby-10.10.2.0.jar:/Users/luhuijun/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.6/datanucleus-api-jdo-3.2.6.jar:/Users/luhuijun/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.9/datanucleus-rdbms-3.2.9.jar:/Users/luhuijun/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/Users/luhuijun/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/Users/luhuijun/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/Users/luhuijun/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/Users/luhuijun/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/Users/luhuijun/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/Users/luhuijun/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/Users/luhuijun/.m2/repository/org/apache/calcite/calcite-avatica/1.2.0-incubating/calcite-avatica-1.2.0-incubating.jar:/Users/luhuijun/.m2/repository/org/apache/calcite/calcite-core/1.2.0-incubating/calcite-core-1.2.0-incubating.jar:/Users/luhuijun/.m2/repository/org/apache/calcite/calcite-linq4j/1.2.0-incubating/calcite-linq4j-1.2.0-incubating.jar:/Users/luhuijun/.m2/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/Users/luhuijun/.m2/repository/org/codehaus/janino/commons-compiler/2.7.6/commons-compiler-2.7.6.jar:/Users/luhuijun/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/luhuijun/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/Users/luhuijun/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/luhuijun/.m2/repository/commons-codec/commons-codec/1.10/commons-codec-1.10.jar:/Users/luhuijun/.m2/repository/joda-time/joda-time/2.9.3/joda-time-2.9.3.jar:/Users/luhuijun/.m2/repository/org/jodd/jodd-core/3.5.2/jodd-core-3.5.2.jar:/Users/luhuijun/.m2/repository/org/datanucleus/datanucleus-core/3.2.10/datanucleus-core-3.2.10.jar:/Users/luhuijun/.m2/repository/org/apache/thrift/libthrift/0.9.2/libthrift-0.9.2.jar:/Users/luhuijun/.m2/repository/org/apache/thrift/libfb303/0.9.2/libfb303-0.9.2.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar&quot; com.intellij.rt.execution.application.AppMain SparkSql</div><div class="line">16/12/12 23:46:59 INFO SparkContext: Running Spark version 2.0.1</div><div class="line">16/12/12 23:47:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</div><div class="line">16/12/12 23:47:04 INFO SecurityManager: Changing view acls to: luhuijun</div><div class="line">16/12/12 23:47:04 INFO SecurityManager: Changing modify acls to: luhuijun</div><div class="line">16/12/12 23:47:04 INFO SecurityManager: Changing view acls groups to: </div><div class="line">16/12/12 23:47:04 INFO SecurityManager: Changing modify acls groups to: </div><div class="line">16/12/12 23:47:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(luhuijun); groups with view permissions: Set(); users  with modify permissions: Set(luhuijun); groups with modify permissions: Set()</div><div class="line">16/12/12 23:47:04 INFO Utils: Successfully started service &apos;sparkDriver&apos; on port 55294.</div><div class="line">16/12/12 23:47:04 INFO SparkEnv: Registering MapOutputTracker</div><div class="line">16/12/12 23:47:04 INFO SparkEnv: Registering BlockManagerMaster</div><div class="line">16/12/12 23:47:04 INFO DiskBlockManager: Created local directory at /private/var/folders/nm/3bv6gdms53115l22n2vhsypc0000gn/T/blockmgr-58f045b4-0e51-43fa-80dd-0af1c2482dc4</div><div class="line">16/12/12 23:47:04 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB</div><div class="line">16/12/12 23:47:04 INFO SparkEnv: Registering OutputCommitCoordinator</div><div class="line">16/12/12 23:47:04 INFO Utils: Successfully started service &apos;SparkUI&apos; on port 4040.</div><div class="line">16/12/12 23:47:04 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.3.2:4040</div><div class="line">16/12/12 23:47:04 INFO Executor: Starting executor ID driver on host localhost</div><div class="line">16/12/12 23:47:04 INFO Utils: Successfully started service &apos;org.apache.spark.network.netty.NettyBlockTransferService&apos; on port 55295.</div><div class="line"></div><div class="line">16/12/12 23:47:08 INFO DAGScheduler: ResultStage 6 (show at SparkSql.scala:24) finished in 0.016 s</div><div class="line">16/12/12 23:47:08 INFO DAGScheduler: Job 4 finished: show at SparkSql.scala:24, took 0.019567 s</div><div class="line">16/12/12 23:47:08 INFO CodeGenerator: Code generated in 6.561389 ms</div><div class="line">+-------+</div><div class="line">|   name|</div><div class="line">+-------+</div><div class="line">|Michael|</div><div class="line">|   Andy|</div><div class="line">| Justin|</div><div class="line">+-------+</div><div class="line">结果隐藏在其中根本找不到...</div></pre></td></tr></table></figure></p></div><p class="readmore"><a href="/2016/12/13/IntelliJ-IDEA-消除Spark程序日志中INFO输出/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/12/浅谈事务和锁/">浅谈事务和锁</a></h2><div class="post-meta">2016-12-12</div><div class="post-content"><h3 id="本篇文章使用SQL-Server来讲解"><a href="#本篇文章使用SQL-Server来讲解" class="headerlink" title="本篇文章使用SQL Server来讲解"></a>本篇文章使用SQL Server来讲解</h3><p>原因: 是因为SQL Server默认支持悲观并发,并且乐观并发的种类比较多,Mysql和Postgresql直接默认就是乐观并发. 感觉用SQL Server来讲会更加全面, 但是不好的是我早就没有SQL Server的IDE了,因为好几年没有接触过SQL Server数据库了.</p></div><p class="readmore"><a href="/2016/12/12/浅谈事务和锁/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/12/表设计短类型优势/">表设计短类型优势</a></h2><div class="post-meta">2016-12-12</div><div class="post-content"><h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>咱们业务数据库的表字段长度偏长，特别是varchar类型，全部都是varchar（255）；<br>表现的比较慷慨，事实证明短类型有很大的优势。</p></div><p class="readmore"><a href="/2016/12/12/表设计短类型优势/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/12/解决爬虫数据-电影院比价系统-电影院名称不规范问题解决思路/">解决爬虫数据(电影院比价系统)电影院名称不规范问题解决思路</a></h2><div class="post-meta">2016-12-12</div><div class="post-content"><h2 id="1-问题"><a href="#1-问题" class="headerlink" title="1 问题"></a>1 问题</h2><p>各大网站录入电影院，地址没有统一的规范，造成电影票无法比价。</p>
<h2 id="2-解决思路"><a href="#2-解决思路" class="headerlink" title="2  解决思路"></a>2  解决思路</h2><h3 id="2-1-经纬度范围查找"><a href="#2-1-经纬度范围查找" class="headerlink" title="2.1 经纬度范围查找"></a>2.1 经纬度范围查找</h3><p>拿到数据中包含经度维度信息，根据经纬度范围查找锁定这些名字不同的电影院为同一家电影院。</p></div><p class="readmore"><a href="/2016/12/12/解决爬虫数据-电影院比价系统-电影院名称不规范问题解决思路/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/12/MongoDB-分片/">MongoDB 分片</a></h2><div class="post-meta">2016-12-12</div><div class="post-content"><h3 id="1-加host"><a href="#1-加host" class="headerlink" title="1. 加host"></a>1. 加host</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">vi /etc/hosts</div><div class="line">192.168.130.93 mongo1</div><div class="line">192.168.130.94 mongo2</div><div class="line">192.168.130.95 mongo3</div></pre></td></tr></table></figure></div><p class="readmore"><a href="/2016/12/12/MongoDB-分片/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/09/postGis-安装部署-对比geohash性能/">postGis 安装部署,对比geohash性能</a></h2><div class="post-meta">2016-12-09</div><div class="post-content"><h2 id="一、描述"><a href="#一、描述" class="headerlink" title="一、描述"></a>一、描述</h2><p>公司现获取最近楼栋信息用的是mongdb的geohash,想对比一下postgis和geohash的性能,<br>首先假设我们安装好了PostgreSQL 9.5.2和Mongodb 3.0,mongodb的配置就不多少了,<br>他本身集成geohash功能,安装配置也很简单,解压启动就OK了,postgis 相对比较麻烦,<br>文献比较少,它依赖于很多插件(geos, proj,GDAL, libxml2, json-c,postgresql)</p></div><p class="readmore"><a href="/2016/12/09/postGis-安装部署-对比geohash性能/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/08/Sqoop2-同步mysql-至-HDFS/">Sqoop2 同步mysql 至 HDFS</a></h2><div class="post-meta">2016-12-08</div><div class="post-content"><h2 id="1-开启客户端"><a href="#1-开启客户端" class="headerlink" title="1. 开启客户端"></a>1. 开启客户端</h2><p><code>sqoop2-shell</code></p>
<h2 id="2-配置sqoop-server参数"><a href="#2-配置sqoop-server参数" class="headerlink" title="2. 配置sqoop server参数"></a>2. 配置sqoop server参数</h2><p><code>sqoop:000&gt; set server --host luhuijundeMacBook-Pro.local --port 12000 --webapp</code></p></div><p class="readmore"><a href="/2016/12/08/Sqoop2-同步mysql-至-HDFS/">阅读更多</a></p></div><nav class="page-navigator"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">下一页</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/MongoDB/" style="font-size: 15px;">MongoDB</a> <a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/Sqoop/" style="font-size: 15px;">Sqoop</a> <a href="/tags/postgis/" style="font-size: 15px;">postgis</a> <a href="/tags/数据库原理/" style="font-size: 15px;">数据库原理</a> <a href="/tags/Performance/" style="font-size: 15px;">Performance</a> <a href="/tags/Work/" style="font-size: 15px;">Work</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/15/Mysql5-6-GTID-半同步复制配置/">Mysql5.6 GTID 半同步复制配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/14/MySQL-误操作后如何快速恢复数据/">MySQL 误操作后如何快速恢复数据</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/13/Mac上安装单机版Spark/">Mac上安装单机版Spark</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/13/IntelliJ-IDEA-消除Spark程序日志中INFO输出/">IntelliJ IDEA 消除Spark程序日志中INFO输出</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/12/浅谈事务和锁/">浅谈事务和锁</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/12/表设计短类型优势/">表设计短类型优势</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/12/解决爬虫数据-电影院比价系统-电影院名称不规范问题解决思路/">解决爬虫数据(电影院比价系统)电影院名称不规范问题解决思路</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/12/MongoDB-分片/">MongoDB 分片</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/09/postGis-安装部署-对比geohash性能/">postGis 安装部署,对比geohash性能</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/08/Sqoop2-同步mysql-至-HDFS/">Sqoop2 同步mysql 至 HDFS</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://qinyueming.cc/" title="秦悦明的运维笔记" target="_blank">秦悦明的运维笔记</a><ul></ul><a href="http://www.sunxing.cc/" title="孙星的个人博客~" target="_blank">孙星的个人博客~</a><ul></ul><a href="http://sate-z.github.io/" title="郑卫星的技术博客" target="_blank">郑卫星的技术博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">huijun's blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>